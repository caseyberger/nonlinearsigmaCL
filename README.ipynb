{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdcfde35-a175-460c-bb77-923580bafd08",
   "metadata": {},
   "source": [
    "# Simulation and Analysis Code for $2D$ $O(3)$ Nonlinear Sigma Model with Topological Term $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d3f9f-040a-4a03-80f1-6cefd1af5660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulation code for Monte Carlo approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee512d33-d8b1-4cf5-a788-0915b300712d",
   "metadata": {},
   "source": [
    "This approach uses a conventional Monte Carlo simulation with a Metropolis step to simulate the $2D$ $\\mathcal{O}(3)$ nonlinear sigma model where the topological term $\\theta$ is assigned an imaginary value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f3b10-e15d-472a-b940-dd198d4033a0",
   "metadata": {},
   "source": [
    "### Code documentation: nonlinearsigma.cpp\n",
    "** Coming soon **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5532f9b-4315-42fd-88e8-12920f5f0b18",
   "metadata": {},
   "source": [
    "### Code documentation: lattice.cpp\n",
    "** last updated November 8, 2023 **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ff9f9-0366-4d17-8dd4-b3da78eab42a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Go through and figure out which - if any - of these functions are never referenced. Move them to a testing class or remove them entirely</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b250dfa-7ffe-4d01-96d7-5215d84a25da",
   "metadata": {},
   "source": [
    "#### Constructor <a id='constructor'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b961d-366c-4a78-b391-dc4a2a96fe37",
   "metadata": {},
   "source": [
    "```cpp\n",
    "    Lattice::Lattice(int length, double beta, double itheta){\n",
    "        Lattice::setLength(length); //set length\n",
    "        Lattice::setBeta(beta); //set beta\n",
    "        Lattice::setiTheta(itheta); //set itheta\n",
    "        Lattice::setnTherm(1000); //set therm steps to default number\n",
    "        Lattice::setnMC(1000); //set Monte Carlo steps to default number\n",
    "        Lattice::setFreq(100); //set frequency between saved configs to default number\n",
    "        Lattice::generateFilename_();\n",
    "        fixedr_ = false; //this should only be set to true when testing\n",
    "        use_arcsin_ = true;\n",
    "    }\n",
    "```\n",
    "The constructor takes in the length of the lattice (we are using a square lattice, so length is used for x and y lengths), the value of beta, and the value of itheta. It then sets those three parameters, sets a default number of thermalization steps, Monte Carlo steps, and frequency for saving the lattice configurations and observables.\n",
    "\n",
    "The functions ```setLength```, ```setBeta```, ```setiTheta```, ```setnTherm```, ```setnMC```, and ```setFreq``` exist to prevent a segmentation fault when running this code. They provide a way into the memory where these parameters are stored, in order to update and save them properly.\n",
    "\n",
    "<div class=\"alert alert-warning\">Something to consider: should you take in the thermalization steps, MC steps, and freq at this point? What purpose does waiting on those have, or is this a holdover from early testing activities?</div>\n",
    "\n",
    "The next thing the constructor does is generate the filename, which is described in more detail in [this section](#generateFilename). This way, as soon as the lattice object is constructed, a filename exists for the output.\n",
    "\n",
    "Then it sets ```fixedr_``` to ```false``` -- this means that we will use the random number generator as usual instead of forcing a pre-set value for the two random numbers (we would only want to fix those numbers in very rare testing conditions). This is currently used in [fixRNG](#fixRNG), [freeRNG](#freeRNG), and [exceptionalConfig](#exceptionalConfig).\n",
    "\n",
    "<div class=\"alert alert-warning\">What is this doing in exceptionalConfig? Do we need it there?</div>\n",
    "\n",
    "Finally, it sets our preference for whether to use arccos or arcsin to calculate QL on the triangles -- the default is to use arcsin, but we can change that setting with the function [setTrig](#setTrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e8d77-5421-4928-acf8-c1ffdd276ac1",
   "metadata": {},
   "source": [
    "#### various set param functions <a id = 'setparams'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e27f6-eb8f-4229-b3c1-01b864eabae1",
   "metadata": {},
   "source": [
    "Each of the functions below allows us to change one of the parameters given for the simulation. These functions are useful when testing the code, as it allows us to update the default values of each of the simulation parameters.\n",
    "\n",
    "Each of these functions has the same basic steps, which are to update the stored attribute in the object and then generate a new filename (as the parameters are listed in the filename). In addition, ```setLength``` also initializes the lattice, since the length of the lattice determines how many spins are on the lattice and the whole lattice must be reset when the length changes.\n",
    "\n",
    "```cpp\n",
    "void Lattice::setLength(int length){\n",
    "        //tested 6/1/2023\n",
    "        length_ = length;\n",
    "        Lattice::generateFilename_();\n",
    "        Lattice::initialize();\n",
    "    }\n",
    "```\n",
    "```cpp\n",
    "    void Lattice::setBeta(double beta){\n",
    "        //tested 6/1/2023\n",
    "        beta_ = beta;\n",
    "        Lattice::generateFilename_();\n",
    "    }\n",
    "```\n",
    "```cpp \n",
    "    void Lattice::setiTheta(double itheta){\n",
    "        //tested 6/1/2023\n",
    "        itheta_ = itheta;\n",
    "        Lattice::generateFilename_();\n",
    "    }\n",
    "```\n",
    "```cpp   \n",
    "    void Lattice::setnTherm(int ntherm){\n",
    "        nTherm_ = ntherm;\n",
    "        Lattice::generateFilename_();\n",
    "    }\n",
    "```\n",
    "```cpp    \n",
    "    void Lattice::setnMC(int nMC){\n",
    "        nMC_ = nMC;\n",
    "        Lattice::generateFilename_();\n",
    "    }\n",
    "```\n",
    "```cpp    \n",
    "    void Lattice::setFreq(int freq){\n",
    "        freq_ = freq;\n",
    "        Lattice::generateFilename_();\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6191f6-798c-4b5f-a16a-067271b0b72d",
   "metadata": {},
   "source": [
    "#### setTrig <a id = 'setTrig'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bde0e4-1ac8-40cb-be41-b3506e1250c4",
   "metadata": {},
   "source": [
    "This function allows us to change our default use of arcsin to arccos by passing ```use_arcsin = false``` into this function. We use this when performing tests on QL.\n",
    "```cpp\n",
    "    void Lattice::setTrig(bool use_arcsin){\n",
    "        use_arcsin_ = use_arcsin;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c188a-345b-44bf-8bf6-f7d7d18b9a0d",
   "metadata": {},
   "source": [
    "#### fixRNG <a id = 'fixRNG'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7a0a3-5b3e-492b-8a18-6689b5a5e52c",
   "metadata": {},
   "source": [
    "This function allows us to set our random numbers to pre-specified values. This is only used when testing to remove the randomness inherent in the model.\n",
    "```cpp    \n",
    "    void Lattice::fixRNG(double r1, double r2){\n",
    "        //tested 6/1/2023\n",
    "        fixedr_ = true;\n",
    "        r1_ = r1;\n",
    "        r2_ = r2;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75651e-6eef-48aa-b623-9298dd2399be",
   "metadata": {},
   "source": [
    "#### freeRNG <a id = 'freeRNG'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca5548-1378-45cb-ae88-42a9d8c2cc3b",
   "metadata": {},
   "source": [
    "This allows us to undo fixing the random numbers, should we wish to perform a test afterwards that requires a random number.\n",
    "```cpp   \n",
    "    void Lattice::freeRNG(){\n",
    "        //tested 6/1/2023\n",
    "        fixedr_ = false;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119897e-4326-4f17-933e-44ef8888bf2c",
   "metadata": {},
   "source": [
    "#### various get parameter functions <a id = 'getparams'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecda89-4281-4f65-adf5-e1d3168671dc",
   "metadata": {},
   "source": [
    "The below functions all perform the same operation: fetching the internal attribute.\n",
    "\n",
    "<div class =\"alert alert-warning\">Investigate whether this is the proper practice -- I recall it helps prevent seg faults, but also am able to use length_ directly in the for loops later? Is that an internal v external access issue? </div>\n",
    "\n",
    "```cpp\n",
    "    int Lattice::getLength(){\n",
    "        //tested 6/1/2023\n",
    "        return length_;\n",
    "    }\n",
    "    \n",
    "    double Lattice::getBeta(){\n",
    "        //tested 6/1/2023\n",
    "        return beta_;\n",
    "    }\n",
    "    \n",
    "    double Lattice::getiTheta(){\n",
    "        //tested 6/1/2023\n",
    "        return itheta_;\n",
    "    }\n",
    "    \n",
    "    int Lattice::getnTherm(){\n",
    "       return nTherm_; \n",
    "    }\n",
    "    \n",
    "    int Lattice::getnMC(){\n",
    "        return nMC_;\n",
    "    }\n",
    "    \n",
    "    std::string Lattice::getFilename(){\n",
    "        return filename_;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253fcf87-c818-4597-a803-949498ddc002",
   "metadata": {},
   "source": [
    "#### getFilename <a id = \"getFilename\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7068ec2-98c2-433c-8f4c-f84d74d05446",
   "metadata": {},
   "source": [
    "This fetches the internal class attribute of the filename, which is generated in [generateFilename](#generateFilename). See [this section](#getparams) for more on why we use getFilename instead of referencing the attribute directly.\n",
    "```cpp\n",
    "std::string Lattice::getFilename(){\n",
    "        return filename_;\n",
    "    }\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77231a-4583-4f91-907f-e3e07e772ca9",
   "metadata": {},
   "source": [
    "#### getPhi <a id = \"getPhi\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9c0b9-d360-45f3-993f-7961daa8ca3e",
   "metadata": {},
   "source": [
    "This fetches the three-component vector phi at site (i,j).  See [this section](#getparams) for more on why we use getPhi instead of referencing the attribute directly. \n",
    "```cpp\n",
    "   \n",
    "    Lattice::field Lattice::getPhi(int i, int j){\n",
    "        //tested 5/30/2023\n",
    "        return grid_[i][j];\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d851f87-2e79-4e43-ae70-d742efe16d54",
   "metadata": {},
   "source": [
    "#### getRandNums <a id = \"getRandNums\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee9629-11e4-439c-afe6-894f80bedbe7",
   "metadata": {},
   "source": [
    "This fetches the two random numbers most recently used to generate our field vectors. <div class=\"alert alert-warning\">Consider removing this or moving it to a testing class if you make one </div>\n",
    "```cpp\n",
    "    double* Lattice::getRandNums(){\n",
    "        //tested 6/1/2023\n",
    "        static double r[2] = {r1_, r2_};\n",
    "        return r;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460c601-5f04-4d9e-8300-ee9369e1b70e",
   "metadata": {},
   "source": [
    "#### getPhiTot <a id = \"getPhiTot\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95d86c-fd95-4f3b-9377-0f1d9bcc19b4",
   "metadata": {},
   "source": [
    "This calculates the total magnitude of phi on the lattice. \n",
    "\n",
    "<div class=\"alert alert-warning\">Currently this is one of our outputs for our observables, but is used nowhere else inside the code. Consider removing this or moving it to a testing class if you make one </div>\n",
    "\n",
    "```cpp\n",
    "    double Lattice::getPhiTot(){\n",
    "        //tested 6/1/2023\n",
    "        //double phi_tot = 0.;\n",
    "        double phi_tot(0.);//optimization 7/4/23\n",
    "        #pragma omp parallel for collapse(2) default(none) shared(length_) reduction(+:phi_tot)\n",
    "        for(int i = 0; i < length_; i++){\n",
    "            for(int j = 0; j < length_; j++){\n",
    "                field phi(Lattice::getPhi(i,j)); \n",
    "                phi_tot += dot(phi,phi);\n",
    "            }\n",
    "        }\n",
    "        return phi_tot;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4eac2-463e-4fd3-98e0-69965a197b52",
   "metadata": {},
   "source": [
    "#### getAvgG <a id = \"getAvgG\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b1a6f-9f34-4989-a740-fad1f5dd2405",
   "metadata": {},
   "source": [
    "This fetches the internal attribute which is the average correlation function at site (i,j).\n",
    "\n",
    "```cpp\n",
    "    double Lattice::getAvgG(int i, int j){\n",
    "        //double Gij = Gij_[i][j];\n",
    "        double Gij(Gij_[i][j]);//optimization 7/4/23\n",
    "        return Gij;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72639584-c3c2-402d-aa46-bd832eaf9be9",
   "metadata": {},
   "source": [
    "#### clean <a id = \"clean\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b970be9-28a7-4aba-aa6a-2fdce0828355",
   "metadata": {},
   "source": [
    "This function creates a shuffled array of all the lattice sites, so it moves randomly on the lattice.\n",
    "\n",
    "It sets a limit on number of attempts at fixing exceptional configurations, and then loops over the entire lattice (using the randomized array).\n",
    "\n",
    "At each site, it checks whether the triangles violate the conditions that allow us to generate integer values for QL. \n",
    "\n",
    "If either condition is violated, we mark that configuration as exceptional and generate a new field at the site. \n",
    "\n",
    "We then check again, continuing until we find a non-exceptional configuration or we reach our limit.\n",
    "\n",
    "We then print to the console how many attempts were required to find a non-exceptional configuration. This is just in hopes that we might be able to figure out where things are going particularly poorly.\n",
    "\n",
    "This function should not be used during the Metropolis step, but only during the initialization step, as the Metropolis step has additional conditions for accepting or rejecting a change to the configuration.\n",
    "\n",
    "\n",
    "<div class = \"alert alert-warning\"> To do: make a [removeExceptional](#removeExceptional) function that modularizes that while loop.</div>\n",
    "\n",
    "```cpp\n",
    "    void Lattice::clean(){\n",
    "        //cleaning the lattice means removing exceptional configurations\n",
    "        int nsites(length_*length_); \n",
    "        std::vector<int> site_arr(nsites);\n",
    "        std::iota(site_arr.begin(), site_arr.end(), 0);     \n",
    "        shuffle(site_arr.begin(), site_arr.end(), std::default_random_engine(1232));\n",
    "        \n",
    "        int exc_lim(1000000);\n",
    "\n",
    "        for(unsigned int n = 0; n < site_arr.size(); n++){\n",
    "            int i(site_arr[n]/length_);\n",
    "            int j(site_arr[n]%length_);\n",
    "            bool exceptional_config = true;\n",
    "            int exc_count = 0;\n",
    "            while (exceptional_config){\n",
    "                if (Lattice::exceptionalConfig(i,j,0) or Lattice::exceptionalConfig(i,j,1)){\n",
    "                    exceptional_config = true;\n",
    "                    exc_count++;\n",
    "                    //update lattice\n",
    "                    field phi_new = Lattice::makePhi_();\n",
    "                    grid_[i][j][0] = phi_new[0];\n",
    "                    grid_[i][j][1] = phi_new[1];\n",
    "                    grid_[i][j][2] = phi_new[2]; \n",
    "                }\n",
    "                else{\n",
    "                    exceptional_config = false;\n",
    "                }\n",
    "                if (exc_count > exc_lim){\n",
    "                    break;\n",
    "                }\n",
    "            }//while still exceptional at i,j\n",
    "            std::cout << \"Num attempts at non-exceptional at site (i,j) = \";\n",
    "            std::cout << i << \",\" << j << \"was \" << exc_count << std::endl;\n",
    "        }//loop over sites\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be7f15-9724-4d04-9ac0-17f6410502b3",
   "metadata": {},
   "source": [
    "#### removeExceptional <a id =\"removeExceptional\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d845b9-15af-4044-824b-ee5fd78c1fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "367463de-d9dc-4bd5-b7b5-4e834b25aef7",
   "metadata": {},
   "source": [
    "#### initialize <a id = \"initialize\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca533d1-52ee-4aea-a857-03d0ff6b955b",
   "metadata": {},
   "source": [
    "This function first initializes a 2D grid (using C++ vectors), where each entry in our grid is of the custom field type (a 3D array of doubles, representing our 3 components of $\\phi$).\n",
    "\n",
    "It then initializes a similar 2D grid, but each entry is just a double. This will store the value of the correlation function at that point.\n",
    "\n",
    "Next, it loops over i and j (x and y), and at each site (i,j), it generates a 3-component field phi using the [makePhi](#makePhi) function and saves that field into the 2D grid.\n",
    "\n",
    "It also initializes the correlation function to 0 at each site (i,j), as the correlation function cannot be calculated yet.\n",
    "\n",
    "After the loops over i and j are complete, the lattice grid of phi vectors and the lattice grid of correlation function, G, are saved to their respective internal attributes (```grid_``` and ```Gij_```).\n",
    "\n",
    "Next, the triangles that we use to calculate $Q_L$ are generated, and their coordinates saved. This happens in the [makeTriangles](#makeTriangles) function.\n",
    "\n",
    "This is the current version of this function:\n",
    "```cpp\n",
    "void Lattice::initialize(){\n",
    "        //tested 5/30/2023\n",
    "        std::vector < std::vector < Lattice::field > > grid;\n",
    "        std::vector < std::vector < double > > Gij;\n",
    "        for(int i = 0; i < length_; i++){\n",
    "            std::vector <double> Gj;\n",
    "            std::vector < Lattice::field > gridj;\n",
    "            for (int j = 0; j<length_; j++){\n",
    "                field phi = Lattice::makePhi_();\n",
    "                gridj.push_back(phi);\n",
    "                Gj.push_back(0.);\n",
    "            }\n",
    "            Gij.push_back(Gj);\n",
    "            grid.push_back(gridj);\n",
    "        }\n",
    "        grid_ = grid;\n",
    "        Gij_ = Gij;\n",
    "        Lattice::makeTriangles_();\n",
    "        Lattice::zeroCount();\n",
    "    }\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\"> The function clean() follows this, which goes through the entire lattice and checks for exceptional configurations and tries to remove them. We should consider adding that to initialization itself, and writing a modular function that checks for exceptional configurations that we can use in both the clean() function and in the metropolis step.\n",
    "\n",
    "Consider also calculating Gij here? You initialize everything to 0, but it's not actually 0. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acaf8f-192a-482a-88a9-9d68baa38b7e",
   "metadata": {},
   "source": [
    "#### makeTriangles <a id = \"makeTriangles\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d28de-19d2-4ff9-aa07-1492dd6d3b26",
   "metadata": {},
   "source": [
    "#### generateFilename <a id='generateFilename'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ac9cb-344b-4a6a-90b0-d3a3a7abfd72",
   "metadata": {},
   "source": [
    "#### exceptionalConfig<a id = 'exceptionalConfig'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794117e-fb84-4a56-961f-33acfdfd2559",
   "metadata": {},
   "source": [
    "### Code documentation: mathlib.cpp <a id = \"mathlib\"> </a>\n",
    "** coming soon **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f1fad-7431-4c70-bbfc-3df59823a4e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Running the simulation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da23c0-3ca3-4224-93be-660676fbacb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Makefile flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e133b9-bdb4-4e3c-bd80-25e7dd926550",
   "metadata": {},
   "source": [
    "The code is written in C++ and OpenMP and can be compiled with numerous flags.\n",
    "\n",
    "```bash\n",
    "USE_OMP ?= TRUE\n",
    "USE_GPROF ?= FALSE\n",
    "USE_TEST_PRINT_STATEMENTS ?= FALSE\n",
    "USE_EXTREME_TEST_CONDITION ?= FALSE\n",
    "USE_CHECK_QL_COS ?= FALSE\n",
    "USE_CONST_RN ?= FALSE\n",
    "```\n",
    "\n",
    "The first flag \"USE_OMP\" toggles whether to implement the parallelization in the code. It should be set to \"TRUE\" if you want to run the simulation in parallel. This is highly recommended for large lattices as the scaling is very poor in series.\n",
    "\n",
    "If you wish to profile the code, set the second flag \"USE_GPROF\" to \"TRUE\". This sets the correct compiler flags so that you can generate the profiling output. To view the output after the code has run, go to the directory in which you have the executable and run the command\n",
    "```bash\n",
    "gprof -l nonlinearsigma gmon.out > profiling_results.txt\n",
    "```\n",
    "You will then be able to see the profiling report. In general, you should set \"USE_GPROF\" to false, unless you are looking to optimize the code or troubleshoot it.\n",
    "\n",
    "The flag \"USE_TEST_PRINT_STATEMENTS\" activates print statements throughout the code. This is useful for debugging, but should generally be set to FALSE as it slows down the code.\n",
    "\n",
    "If you run into major problems, set \"USE_EXTREME_TEST_CONDITION\" to TRUE. This will run a testing suite built into the code, but will not run the usual simulation. This can help you identify problems in the code, and the testing suite is a function inside the main function, which can be modified as needed to add more tests.\n",
    "\n",
    "To switch from using arcsin to calculate $Q_{L}$ to using arccos, set \"USE_CHECK_QL_COS\" to TRUE. In general, this should be set to FALSE< as we want to use arcsin due to its useful symmetry.\n",
    "\n",
    "Finally, if you want to remove the random number generation and use a constant value for the random numbers, set \"USE_CONST_RN\" to true. This should only be done when testing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a05c8-0567-4c06-a500-81504bf667f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compiling the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4ad29-fa67-40a9-963e-17fc67e93b1c",
   "metadata": {},
   "source": [
    "Once you have set the flags you want to use, you can compile the code by typing\n",
    "\n",
    "```bash\n",
    "make -f make_sigma\n",
    "```\n",
    "It can be useful to run \n",
    "\n",
    "```bash\n",
    "make -f make_sigma clean\n",
    "```\n",
    "first to clear out old .o files that might not be updated otherwise.\n",
    "\n",
    "Once you have compiled the code, you should have an executable by the name of ```nonlinearsigma``` which you will use to run the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65455eb3-f0ec-4c15-9daa-386088ff5776",
   "metadata": {},
   "source": [
    "### Other important things to note before running the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62289d5-34c2-49d3-bad7-b7f18c0bae56",
   "metadata": {},
   "source": [
    "The simulation requires a list of parameters. We give those to the code through the text file ```inputs.txt```. That file consists of a list of parameter keywords and a value. Be very careful not to change the format of this document, only the numbers, otherwise the simulation won't be able to understand what values get assigned to what parameters. \n",
    "\n",
    "The file ```inputs.txt``` should look like this\n",
    "\n",
    "```\n",
    "L = 10\n",
    "beta = 1.6\n",
    "itheta = 1.\n",
    "ntherm = 1000\n",
    "nMC = 1000\n",
    "freq = 100\n",
    "```\n",
    "Where ```L``` gives the length of the square lattice, ```beta``` is $\\beta = 1/g_{L}$ and should be set to 1.6, ```itheta``` is the imaginary value given for the topological term and is given in fractions of $\\pi$ (so you should enter 0.5 if you want $i \\theta = \\pi/2$), ```ntherm``` is the number of steps you want the simulation to take for thermalization, ```nMC``` is the number of steps in the Monte Carlo loop after thermalization, and ```freq``` sets the number of steps between saved configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96d86b-7b56-44b7-950b-661184b8e87a",
   "metadata": {},
   "source": [
    "### Running the code -- single job in interactive node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019052a4-051e-4d54-8c6e-ceb9f000019e",
   "metadata": {},
   "source": [
    "If you want to run this in an interactive node to test, you can request an interactive node with the following command:\n",
    "\n",
    "```bash\n",
    "salloc --cpus-per-task=1 --time=00:30:00\n",
    "```\n",
    "where you can adjust the number of cpus per task if you want to run the parallelized code and the time requested is in format hh:mm:ss\n",
    "\n",
    "You can run the job using the command\n",
    "\n",
    "```bash\n",
    "./nonlinearsigma inputs.txt\n",
    "```\n",
    "```nonlinearsigma``` is the name of the executable created when you compiled the code, and inputs.txt is the list of inputs mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afeaa6d-f429-4abf-8907-8c332d05b4e2",
   "metadata": {},
   "source": [
    "### Running the code -- single SLURM submission "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355d437-a547-410c-ae57-cbee6abd16c4",
   "metadata": {},
   "source": [
    "Once you're comfortable with the code and want to submit a job that's longer than your interactive session (or one that may need to run overnight, etc), you do that by writing a SLURM script and sending that script to the scheduler.\n",
    "\n",
    "The script is called ```submit_sigma.sh``` and looks like this:\n",
    "```bash\n",
    "#SBATCH --job-name=nonlinearsigma_omp_test           # Job name\n",
    "#SBATCH --mail-type=ALL                              # Mail events (NONE, BEGIN, END, FAIL, ALL)\n",
    "#SBATCH --mail-user=cberger@smith.edu                # Where to send mail\n",
    "#SBATCH --partition=phyq                             # Which partition to use\n",
    "#SBATCH --nodes=1                                    # Number of nodes\n",
    "#SBATCH --cpus-per-task=1                           # Number of threads per task (OpenMP)\n",
    "#SBATCH --mem=1gb                                    # Job memory request\n",
    "##SBATCH --time=05:00:00                             # Time limit hrs:min:sec\n",
    "#SBATCH --output=nonlinearsigma_omp_test_%j.log      # Standard output \n",
    "#SBATCH --error=err_nonlinearsigma_omp_test_%j.log   # Standard output and error log\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "echo \"Running nonlinear sigma on single CPU core\"\n",
    "\n",
    "/usr/bin/time -v ./nonlinearsigma inputs.txt\n",
    "\n",
    "date\n",
    "```\n",
    "\n",
    "Let's walk through what this script does.\n",
    "\n",
    "The first line:\n",
    "```bash\n",
    "#SBATCH --job-name=nonlinearsigma_omp_test           # Job name\n",
    "```\n",
    "Assigns a name to the job, which can help you keep track of what is running in the queue. I tend to name all my jobs in a certain phase of the work the same thing (e.g. \"nonlinearsigma_small_L_tests\" if I'm testing out the script on small lattices or \"nonlinearsigma_first_production_run\" if I'm starting to take data for real). This is just for your own information, so name it whatever you'd like.\n",
    "\n",
    "The next two lines\n",
    "```bash\n",
    "#SBATCH --mail-type=ALL                              # Mail events (NONE, BEGIN, END, FAIL, ALL)\n",
    "#SBATCH --mail-user=cberger@smith.edu                # Where to send mail\n",
    "```\n",
    "tell SLURM who to email and when to email you. I have it set to email me at my Smith email anytime a job starts, ends, or fails. I find this helpful, especially if trouble arises, but it's your choice what to put here (just don't leave my email address in!).\n",
    "\n",
    "The next line\n",
    "```bash\n",
    "#SBATCH --partition=phyq                             # Which partition to use\n",
    "```\n",
    "sends the jobs to the partition that belongs to the physics department. We have priority on this node, but we can request time on other nodes if we really need to. We'd need to talk to CATS about that if we wanted to do it.\n",
    "\n",
    "The next lines specify the code's needs:\n",
    "```bash\n",
    "#SBATCH --nodes=1                                    # Number of nodes\n",
    "#SBATCH --cpus-per-task=1                           # Number of threads per task (OpenMP)\n",
    "#SBATCH --mem=1gb                                    # Job memory request\n",
    "```\n",
    "Since we are using OpenMP for parallelization, we only need one node, but we will want to change ```bash --cpus-per-task``` to something larger for OpenMP. Unless doing a very large lattice (L > 100), I tend to ask for 30 CPUs per task, which allows for 2 jobs to run at a time on each node. If you're doing something large, you might want to consider asking for 60 CPUs per task, which will occupy an entire node.\n",
    "\n",
    "This line\n",
    "```bash\n",
    "##SBATCH --time=05:00:00                             # Time limit hrs:min:sec\n",
    "```\n",
    "sets a time limit -- it will cut off your code when that limit is reached, whether it is done or not. Note there is an extra `#` here -- that means it's commented out, so it will not have a time limit. I tend to only use the time limits when testing.\n",
    "\n",
    "These next two lines\n",
    "```bash\n",
    "#SBATCH --output=nonlinearsigma_omp_test_%j.log      # Standard output \n",
    "#SBATCH --error=err_nonlinearsigma_omp_test_%j.log   # Standard output and error log\n",
    "``` \n",
    "give names to the output and error files. These files are created when the code runs and can help you debug if things go wrong.\n",
    "\n",
    "All the above were instructions for SLURM, which schedules jobs on the machine's available resources. Now we get into the commands to actually run the code.\n",
    "\n",
    "```bash\n",
    "pwd; hostname; date\n",
    "```\n",
    "This just prints where the job is being run from and the date and time before the job starts.\n",
    "\n",
    "```bash\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "```\n",
    "this sets the number of threads in OpenMP equal to the number of CPUs per task you assigned above.\n",
    "\n",
    "```bash\n",
    "echo \"Running nonlinear sigma\"\n",
    "\n",
    "/usr/bin/time -v ./nonlinearsigma inputs.txt\n",
    "```\n",
    "This prints out an annoucement that you're starting the job, which is useful in the logfile, and then runs the simulation with the inputs file. Make sure you have the inputs file and the executable in the same folder as the SLURM script so the computer can find them.\n",
    "\n",
    "And finally\n",
    "```bash\n",
    "date\n",
    "```\n",
    "we print the datetime stamp at the end of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2caf7f5-a9fd-4fa8-af14-1f122340fed9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running the code -- batch SLURM submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ccdae-80ba-49e1-8a2f-daa7d4386c45",
   "metadata": {},
   "source": [
    "Each inputs file is one set of parameters, and we need to get lots of data. If you're not interested in manually setting up these SLURM scripts, input files, etc by hand, I don't blame you. That's why I wrote a Python code to do most of the work for you.\n",
    "\n",
    "In this code, you specify what parameters you want to run, and the script creates all the appropriate directories and puts the correct inputs file, slurm script, and the executable in each directory. You still have to go in and submit the files yourself, but it's much easier than writing all these scripts yourself.\n",
    "\n",
    "The script is called ```create_input_files.py``` and here is the part you will need to modify:\n",
    "\n",
    "```python\n",
    "#beta = 1/g = 1.6\n",
    "beta = 1.6\n",
    "#number of steps in thermalization\n",
    "ntherm = 4000\n",
    "#number of monte carlo steps\n",
    "nMC = 10000\n",
    "#number of steps between samples\n",
    "freq = 100\n",
    "#list of values for lattice length L\n",
    "L_list = [10,40,80,120,180]\n",
    "#list of values for itheta (as fractions of pi)\n",
    "itheta_list = [0.0,0.125,0.25,0.375,0.5,0.625,0.75,0.875,1.,1.125]\n",
    "\n",
    "script_name = \"nonlinearsigma\"\n",
    "job_name = \"nlsigma_prelim_tests\"\n",
    "email = \"cberger@smith.edu\"\n",
    "num_cpus = 30\n",
    "\n",
    "```\n",
    "Beta, ntherm, nMC, and freq all take one number as input, but you can create a list of the number of lattice lengths you want, and the values for itheta (remember these are fractions of pi). \n",
    "\n",
    "```script_name``` is the executable, so it should be \"nonlinearsigma\", but ```job_name``` is what will be put in for the job name in the SLURM script. Similarly, you can enter the email address you want included in the SLURM script and choose how many CPUs you want.\n",
    "\n",
    "Once you've modified this script to have the values you want, put it in a directory for this batch. I tend to name those something like ```run_yyymmdd```. Also in that directory should be the executable, so copy that in once you've compiled the code.\n",
    "\n",
    "Then, inside the batch directory, go ahead and run the python script\n",
    "\n",
    "```bash\n",
    "python create_input_files.py\n",
    "```\n",
    "\n",
    "When it's done, you should see the subdirectories created -- one for each job. You need to go into each subdirectory to submit the jobs using\n",
    "\n",
    "```bash\n",
    "sbatch submit_sigma.sh\n",
    "```\n",
    "and it will submit the jobs to the scheduler.\n",
    "\n",
    "You can run this with \n",
    "```bash\n",
    "sbatch submit_sigma.sh\n",
    "```\n",
    "and you can check the status of your jobs any time with the command\n",
    "```bash\n",
    "squeue -u your_username\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bc050-a832-481b-9ae1-583a53d02fbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python Code for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b66bc9-39fa-4947-b729-a9402019265d",
   "metadata": {},
   "source": [
    "There are a number of Jupyter Notebooks prepared to explore the data that comes out of the simulation. These are all located in the Analysis folder. There is also a Python class, LatticeData.py, which creates an analyzer object that has internal functions for analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce14a98-0091-41a6-8760-62b79073d257",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LatticeData.py - Data Analyzer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77ded4-03b6-4148-8945-ae5c5ce2e745",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing and initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954184d7-b929-48cf-8e8d-3f1a083e5f6b",
   "metadata": {},
   "source": [
    "This is a Python class. You can create a lattice data object, which then holds all the functionality you need to analyze and visualize the data. You will need to import this into your notebook like this:\n",
    "```python\n",
    "from LatticeData import *\n",
    "```\n",
    "\n",
    "You will want to also import the following:\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Matplotlib\n",
    "* Seaborn\n",
    "\n",
    "The simplest way to start now is by initializing the object:\n",
    "\n",
    "``` python\n",
    "analyzer = LatticeData()\n",
    "```\n",
    "You can now do a number of operations with this analyzer. The full list of functions is included later, but if you wanted to get all the data from that folder and put it into a Pandas dataframe, that would look like this:\n",
    "\n",
    "```python\n",
    "df = analyzer.get_data()\n",
    "```\n",
    "\n",
    "There are a number of default settings in this class, which you can change when you initialize. The defaults are:\n",
    "```python\n",
    "analyzer_default = LatticeData(datadir = \"/data/\", header = \"nonlinearsigma_data\",\n",
    "                 dirheader = \"nlsigma_data\", Gheader = \"Gij_avg_nonlinearsigma_data\", \n",
    "                 tol = 0.00001, palette = \"viridis\")\n",
    "```\n",
    "which initializes the following internal variables:\n",
    "```python\n",
    "\n",
    "self.path = os.getcwd()+datadir #location of data\n",
    "self.header = header #set the start of the filename for the data files\n",
    "self.dirheader = dirheader #set the start of the data directory name from the runs\n",
    "self.Gheader = Gheader #set the start of the filename for correlation function files\n",
    "self.tol = tol #set the error range for parameters -- this is for filtering\n",
    "self.palette = palette #option to change seaborn palette\n",
    "self.observables = ['Q_L', 'A_L', 'S_L', 'Xi_L'] #observables whose expectation values can be computed\n",
    "self.parameters = [\"itheta\", \"beta\", \"length\",\"nMC\", \"ntherm\", \"freq\"] #parameters read in by the simulation code\n",
    "```\n",
    "Most of these will not need to be changed, but let's say you want to analyze a special batch of data, which you've stored in a directory called ```data_test```, and you want to use a different visualization palette, you could intialize the object like this:\n",
    "```python\n",
    "analyzer_special = LatticeData(datadir = \"/data_test/\", palette = \"magma\")\n",
    "```\n",
    "(You can choose any [seaborn palette](https://seaborn.pydata.org/tutorial/color_palettes.html) for this)\n",
    "\n",
    "Then when you run the function\n",
    "```python  \n",
    "df = analyzer_special.get_data()\n",
    "```\n",
    "it will aggregate all the data files in the folder ```data_test```.\n",
    "\n",
    "Below is a complete list of functions for the LatticeData class, with a brief description. While Python doesn't have the same public/private distinctions as C++, I've organized them into those same groups. Public functions are things that you may want to use. Private functions are functions that you should never need to call yourself, but are called internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244be6b2-b1b3-4584-969d-caf16f7a08f8",
   "metadata": {},
   "source": [
    "#### Lattice Data Class Built-In Functions (\"Public\" or external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b064276-523d-470d-b85a-823634926d25",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### copy_data_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c0882-d614-4d54-8bd9-08d267ec3e03",
   "metadata": {},
   "source": [
    "```python\n",
    "copy_data_from_directory(self, src_dir, dst_path = None)\n",
    "```\n",
    "This function loops through a specified directory, finds any simulation directories (directions that begin with \"nlsigma_data\" or whatever you have specified under ```dirheader``` in your intialization), and copies the .csv files within those directories to some destination directory. The default destination directory is whatever you've specified for your data directory.\n",
    "    The function requires a source directory to be passed as a string -- this is the directory where you have all your simulation results that you want copied over -- and gives you the option to specify a different destination directory using ```dst_path```)\n",
    "    \n",
    "If some of your simulations are not complete yet (determined by testing whether the .csv has the correct number of lines), this function will not copy those files and will print out the name of the run and how many lines there are in the data output file. For example, the folder ```run_7_18_23_stats``` contains some runs that haven't finished yet. If I try to copy the data from that directory into my data directory:\n",
    "    \n",
    "```python\n",
    "analyzer.copy_data_from_directory(\"run_7_18_23_stats\")\n",
    "```\n",
    "here's what appears printed out:\n",
    "```\n",
    "run L_180_beta_1.600000_itheta_0.000000_ntherm_5000_nMC_50000_freq_100 not yet complete: 378 lines\n",
    "run L_180_beta_1.600000_itheta_2.356194_ntherm_5000_nMC_50000_freq_100 not yet complete: 391 lines\n",
    "run L_180_beta_1.600000_itheta_3.141593_ntherm_5000_nMC_50000_freq_100 not yet complete: 237 lines\n",
    "run L_180_beta_1.600000_itheta_1.570796_ntherm_5000_nMC_50000_freq_100 not yet complete: 381 lines\n",
    "run L_180_beta_1.600000_itheta_0.785398_ntherm_5000_nMC_50000_freq_100 not yet complete: 240 lines\n",
    "```\n",
    "And those runs will not be in the data directory, while completed runs will have been copied in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be54de-5f43-4abc-b25e-3296d52afdb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38426e5a-a4f7-4c89-a54e-5e5e520df3ee",
   "metadata": {},
   "source": [
    "```python\n",
    "all_params(self)\n",
    "```\n",
    "This function collects every unique set of parameters from your default data directory and returns it as a dataframe. It does not take any inputs -- if you want to know what combinations of parameters are in your directory, this function will tell you.\n",
    "    \n",
    "```python\n",
    "params = analyzer.all_params()\n",
    "params.head()\n",
    "```\n",
    "```\n",
    ">\n",
    "    freq\tnMC\tntherm\titheta\tbeta\tlength\n",
    "0\t100.0\t50000.0\t5000.0\t0.785398\t1.6\t20.0\n",
    "1\t100.0\t50000.0\t5000.0\t0.000000\t1.6\t80.0\n",
    "2\t100.0\t50000.0\t5000.0\t0.000000\t1.6\t20.0\n",
    "3\t100.0\t50000.0\t5000.0\t1.570796\t1.6\t40.0\n",
    "4\t100.0\t50000.0\t5000.0\t2.356194\t1.6\t10.0\n",
    "```\n",
    "It also adds a column that tells you what fraction of $\\pi$ $i\\theta$ is, to make it easier to determine what new jobs should be run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ddff3-fe45-47cb-9fae-9262550a93a6",
   "metadata": {},
   "source": [
    "If you want to collect data from more than one run, you can do this by only specifying which parameters you want in your dataframe, and the function will filter the data accordingly.\n",
    "\n",
    "```python\n",
    "param_dict = {\"length\": 10, \"itheta\":2.356194}\n",
    "filtered_data = analyzer.get_data(single_run = False, suppress_output = True, **param_dict)\n",
    "```\n",
    "\n",
    "If you want *all* the data, just leave out the parameter dictionary entirely and it won't filter anything.\n",
    "\n",
    "```python\n",
    "all_data = analyzer.get_data(single_run = False, suppress_output = True)\n",
    "```\n",
    "\n",
    "NOTE: I strongly recommend suppressing output if you are collecting more than 2 or 3 runs, as it will slow the program down and produce a flood of output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a191ab0-066a-4ff6-ada6-5c50a4f330c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f81d8-0ab7-48c7-949c-3121201b7119",
   "metadata": {},
   "source": [
    "```python\n",
    "get_data(self, single_run = False, corr = False, suppress_output = True, **kwargs)\n",
    "```\n",
    "\n",
    "This function will collect raw data from one or more runs and return it as a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5e140-c6eb-4efb-9240-ba2a1fdbbc2f",
   "metadata": {},
   "source": [
    "If you want to just get data from one simulation run (e.g. to check thermalization or autocorrelation), you should set ```single_run``` to ``` True```. If you want the correlation function data from that run, you should set ```corr``` to ```True``` -- otherwise it will return the observable data. If you want it to print out the parameter sets it's putting into the dataset, set ```suppress_output``` to ```False```\n",
    "\n",
    "You then need to specify what the parameters are for the run you want to see. You do this by creating a dictionary. When selecting a single one, you must ensure your dictionary has *all* the parameter values specified. The keys for these values are:\n",
    "* \"length\": length of the lattice in each direction\n",
    "* \"itheta\": value of the imaginary value used for theta -- actual number here, not an integer multiple of pi, but you can always use ```np.pi``` to specify it\n",
    "* \"beta\": for our purposes this will always be 1.6, but you need to specify it anyway\n",
    "* \"nMC\": number of steps in the Monte Carlo loop \n",
    "* \"ntherm\": number of steps in the thermalization loop\n",
    "* \"freq\": frequency with which the configurations were saved\n",
    "\n",
    "If you forget one of these, the function will remind you: \n",
    "\n",
    "```python\n",
    "param_dict = {\"length\": 10, \"freq\": 100, \"itheta\":2.356194, \"beta\":1.6, \"nMC\":50000}\n",
    "one_run = analyzer.get_data(single_run = True, suppress_output = False, **param_dict)\n",
    "\n",
    "```\n",
    "```\n",
    "Missing parameters in input: \n",
    "['ntherm']\n",
    "```\n",
    "So you know now to add in the \"ntherm\" you're looking for. Now it should work:\n",
    "```python\n",
    "param_dict = {\"length\": 10, \"freq\": 100, \"itheta\":2.356194, \"beta\":1.6, \"nMC\":50000, \"ntherm\": 5000}\n",
    "one_run = analyzer.get_data(single_run = True, suppress_output = False, **param_dict)\n",
    "```\n",
    "```\n",
    "freq 100\n",
    "nMC 50000\n",
    "ntherm 5000\n",
    "itheta 2.356194\n",
    "beta 1.6\n",
    "length 10\n",
    "```\n",
    "\n",
    "```python\n",
    "one_run.head(3)\n",
    "```\n",
    "```\n",
    "\tstep\t|phi|\tQ_L\tA_L\tS_L\tXi_L\tF_LRe\tF_LIm\tacc\tdt\t...\tQ_L_ta\tA_L_ta\tS_L_ta\tXi_L_ta\tcorr_length_Re\tcorr_length_Im\tF_Re_py\tF_Im_py\tmass_gap_Re\tmass_gap_Im\n",
    "0\t0\t100.0\t0.479179\t-183.166830\t-184.295868\t45.724903\t3.675149\t8.145972\t0.240000\t0.0\t...\t1\t3\t3\t4\t8.966957\t-3.640801\t0.916337\t0.890996\t0.095738\t0.038872\n",
    "1\t100\t100.0\t0.159302\t-195.846927\t-196.222275\t62.369185\t3.675149\t8.145972\t0.203762\t0.0\t...\t1\t3\t3\t4\t10.472580\t-4.252121\t0.916337\t0.890996\t0.081974\t0.033283\n",
    "2\t200\t100.0\t0.000000\t-199.012224\t-199.012224\t48.119359\t3.675149\t8.145972\t0.207164\t0.0\t...\t1\t3\t3\t4\t9.198745\t-3.734913\t0.916337\t0.890996\t0.093325\t0.037892\n",
    "3\t300\t100.0\t0.312655\t-179.261053\t-179.997729\t46.124447\t3.675149\t8.145972\t0.205681\t0.0\t...\t1\t3\t3\t4\t9.006048\t-3.656673\t0.916337\t0.890996\t0.095322\t0.038703\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b15cc-750e-4c75-b2bb-e5044dde0d92",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### do_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131ecae-84d2-4cb9-9785-fb2b8b6097c7",
   "metadata": {},
   "source": [
    "```python \n",
    "do_stats(self, therm = 0., stack = False, **kwargs)\n",
    "```\n",
    "This function collects data from the directory you specified when you initialized the object. If you want to filter the data by parameters, you just need to enter a parameter dictionary just like when using get_data() above, and it will filter to include only data that matches the parameter values you've entered.\n",
    "\n",
    "Once all the raw data is collected, it will perform some basic statistical analysis. All observables will have a mean and standard error calculated from data after thermalization. If you need to change the thermalization point, you can increase it by changing the ```therm``` argument in the function -- give it the fractional value of the data you want it to drop from the beginning of the dataset. So for example, if you have a run with ```nMC = 1000``` and ```freq = 10```, you will have a total of 100 steps in your dataset. If you set ```therm = 0.2```, it will drop the first 20 steps before computing the mean and standard error.\n",
    "\n",
    "After calculating means and standard errors, it also computes the autocorrelation time (the step at which the observable's autocorrelation value drops below 0.3), and then determines how long that run took to complete, saving that information in seconds, minutes, and hours.\n",
    "\n",
    "It saves all of this along with the parameters used in that run. The result is a very comprehensive dataframe. Here's an example of it run on a data directory with 25 runs in it:\n",
    "\n",
    "```python\n",
    "df_stats = analyzer.do_stats()\n",
    "df_stats.info()\n",
    "```\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 25 entries, 0 to 24\n",
    "Data columns (total 41 columns):\n",
    " #   Column               Non-Null Count  Dtype  \n",
    "---  ------               --------------  -----  \n",
    " 0   length               25 non-null     float64\n",
    " 1   itheta               25 non-null     float64\n",
    " 2   beta                 25 non-null     float64\n",
    " 3   nMC                  25 non-null     float64\n",
    " 4   ntherm               25 non-null     float64\n",
    " 5   freq                 25 non-null     float64\n",
    " 6   |phi|_mean           25 non-null     float64\n",
    " 7   Q_L_mean             25 non-null     float64\n",
    " 8   A_L_mean             25 non-null     float64\n",
    " 9   S_L_mean             25 non-null     float64\n",
    " 10  Xi_L_mean            25 non-null     float64\n",
    " 11  F_LRe_mean           25 non-null     float64\n",
    " 12  F_LIm_mean           25 non-null     float64\n",
    " 13  acc_mean             25 non-null     float64\n",
    " 14  Q_L_ta               25 non-null     float64\n",
    " 15  A_L_ta               25 non-null     float64\n",
    " 16  S_L_ta               25 non-null     float64\n",
    " 17  Xi_L_ta              25 non-null     float64\n",
    " 18  corr_length_Re_mean  25 non-null     float64\n",
    " 19  corr_length_Im_mean  25 non-null     float64\n",
    " 20  F_Re_py_mean         25 non-null     float64\n",
    " 21  F_Im_py_mean         25 non-null     float64\n",
    " 22  mass_gap_Re_mean     25 non-null     float64\n",
    " 23  mass_gap_Im_mean     25 non-null     float64\n",
    " 24  |phi|_std            25 non-null     float64\n",
    " 25  Q_L_std              25 non-null     float64\n",
    " 26  A_L_std              25 non-null     float64\n",
    " 27  S_L_std              25 non-null     float64\n",
    " 28  Xi_L_std             25 non-null     float64\n",
    " 29  F_LRe_std            25 non-null     float64\n",
    " 30  F_LIm_std            25 non-null     float64\n",
    " 31  acc_std              25 non-null     float64\n",
    " 32  corr_length_Re_std   25 non-null     float64\n",
    " 33  corr_length_Im_std   25 non-null     float64\n",
    " 34  F_Re_py_std          25 non-null     float64\n",
    " 35  F_Im_py_std          25 non-null     float64\n",
    " 36  mass_gap_Re_std      25 non-null     float64\n",
    " 37  mass_gap_Im_std      25 non-null     float64\n",
    " 38  time (sec)           25 non-null     float64\n",
    " 39  time (min)           25 non-null     float64\n",
    " 40  time (hr)            25 non-null     float64\n",
    "dtypes: float64(41)\n",
    "memory usage: 8.1 KB\n",
    "\n",
    "```\n",
    "\n",
    "If I only want the analyzed data for runs where the lattice had a length of 20, I could modify this as follows:\n",
    "\n",
    "```python\n",
    "df_stats = analyzer.do_stats(**{\"length\":20})\n",
    "df_stats.info()\n",
    "```\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "Data columns (total 41 columns):\n",
    " #   Column               Non-Null Count  Dtype  \n",
    "---  ------               --------------  -----  \n",
    " 0   length               5 non-null      float64\n",
    " 1   itheta               5 non-null      float64\n",
    " 2   beta                 5 non-null      float64\n",
    " 3   nMC                  5 non-null      float64\n",
    " 4   ntherm               5 non-null      float64\n",
    " 5   freq                 5 non-null      float64\n",
    " 6   |phi|_mean           5 non-null      float64\n",
    " 7   Q_L_mean             5 non-null      float64\n",
    " 8   A_L_mean             5 non-null      float64\n",
    " 9   S_L_mean             5 non-null      float64\n",
    " 10  Xi_L_mean            5 non-null      float64\n",
    " 11  F_LRe_mean           5 non-null      float64\n",
    " 12  F_LIm_mean           5 non-null      float64\n",
    " 13  acc_mean             5 non-null      float64\n",
    " 14  Q_L_ta               5 non-null      float64\n",
    " 15  A_L_ta               5 non-null      float64\n",
    " 16  S_L_ta               5 non-null      float64\n",
    " 17  Xi_L_ta              5 non-null      float64\n",
    " 18  corr_length_Re_mean  5 non-null      float64\n",
    " 19  corr_length_Im_mean  5 non-null      float64\n",
    " 20  F_Re_py_mean         5 non-null      float64\n",
    " 21  F_Im_py_mean         5 non-null      float64\n",
    " 22  mass_gap_Re_mean     5 non-null      float64\n",
    " 23  mass_gap_Im_mean     5 non-null      float64\n",
    " 24  |phi|_std            5 non-null      float64\n",
    " 25  Q_L_std              5 non-null      float64\n",
    " 26  A_L_std              5 non-null      float64\n",
    " 27  S_L_std              5 non-null      float64\n",
    " 28  Xi_L_std             5 non-null      float64\n",
    " 29  F_LRe_std            5 non-null      float64\n",
    " 30  F_LIm_std            5 non-null      float64\n",
    " 31  acc_std              5 non-null      float64\n",
    " 32  corr_length_Re_std   5 non-null      float64\n",
    " 33  corr_length_Im_std   5 non-null      float64\n",
    " 34  F_Re_py_std          5 non-null      float64\n",
    " 35  F_Im_py_std          5 non-null      float64\n",
    " 36  mass_gap_Re_std      5 non-null      float64\n",
    " 37  mass_gap_Im_std      5 non-null      float64\n",
    " 38  time (sec)           5 non-null      float64\n",
    " 39  time (min)           5 non-null      float64\n",
    " 40  time (hr)            5 non-null      float64\n",
    "dtypes: float64(41)\n",
    "memory usage: 1.7 KB\n",
    "```\n",
    "Notice we now only have 5 entries in our dataframe, not 25. We can check that this worked:\n",
    "\n",
    "```python\n",
    "df_stats[\"length\"].unique()\n",
    "```\n",
    "```\n",
    "array([20.])\n",
    "```\n",
    "\n",
    "If you want the data returned using Pandas MultiIndex, set ```stack``` to ```True```, but MultiIndex doesn't always play well with seaborn and other plotting tools, so the default is ```False```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdba58e-f301-4291-9d24-ba562df94cba",
   "metadata": {},
   "source": [
    "##### get_plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec5711-804b-4ba7-b6c5-27930142022e",
   "metadata": {},
   "source": [
    "```python\n",
    "get_plot_data(self, obs = \"Q_L\", L = 10, beta = 1.6, nMC = 10000, ntherm = 1000, freq = 100, stack = False)\n",
    "```\n",
    "This function allows you to get the analyzed data for one observable (you may specify which one, but the default is ```Q_L```) as a function of itheta in order to plot it. You must specify a single value for all other parameters (```L```, ```beta```, ```nMC```, ```ntherm```, ```freq```) or leave them blank to use the defaults.\n",
    "\n",
    "This pulls its data from the internally stored dataframe self.df_stats, which is created when you run the do_stats function. If you have not run that function yet, it will do it for you, with the default settings of ```therm = 0.0``` and ```stack = False```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112dd86-6914-4c54-a27b-f0e2f8e0909e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "This doesn't play nice with MultiIndex right now, so I recommend making sure to do this with the default of \n",
    "   \n",
    "```python\n",
    "stack = False\n",
    "```\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0bb00-d58c-4081-8098-10f32d152644",
   "metadata": {},
   "source": [
    "This function could be modified in order to choose your independent variable, but right now all the plots we are interested in are functions of itheta, so it's unneccesary to plot the observable as a function of any other parameter. Seaborn can be used with the raw data to study systematic effects or other things that may be functions of ```nMC```, ```ntherm``` or ```L```. \n",
    "\n",
    "This returns three items: x, y, and y_err, which can then be plotted immediately with the matplotlib errorbar function.\n",
    "\n",
    "For example, if you wanted to plot ```Q_L``` as a function of ```itheta``` for all the different lengths you have in your data, you would do the following:\n",
    "\n",
    "```python\n",
    "params = analyzer.all_params()\n",
    "lengths = params[\"length\"].unique()\n",
    "colors = sns.color_palette(\"Blues\", len(lengths))\n",
    "observable = \"Q_L\"\n",
    "\n",
    "for n,length in enumerate(lengths):\n",
    "    x,y,err = analyzer.get_plot_data(obs = observable, L = length, beta = 1.6, nMC = 50000, \n",
    "                                     ntherm = 5000, freq = 100)\n",
    "    plt.errorbar(x, y , yerr = err, marker = \".\", ls = \"none\", color = colors[n], label =\"L=\"+str(length))\n",
    "plt.legend()\n",
    "plt.title(observable)\n",
    "plt.show()\n",
    "```\n",
    "And you would get the following output:\n",
    "\n",
    "<img src = \"./Figs_README/QL_v_itheta_example.jpg\">\n",
    "\n",
    "And if you wanted to plot the magnetic susceptibility ```Xi_L``` as a function of ```itheta``` for each length, you would do:\n",
    "\n",
    "```python\n",
    "params = analyzer.all_params()\n",
    "lengths = params[\"length\"].unique()\n",
    "colors = sns.color_palette(\"Reds\", len(lengths))\n",
    "observable = \"Xi_L\"\n",
    "\n",
    "for n,length in enumerate(lengths):\n",
    "    x,y,err = analyzer.get_plot_data(obs = observable, L = length, beta = 1.6, nMC = 50000, \n",
    "                                     ntherm = 5000, freq = 100)\n",
    "    plt.errorbar(x, y , yerr = err, marker = \".\", ls = \"none\", color = colors[n], label =\"L=\"+str(length))\n",
    "plt.legend()\n",
    "plt.title(observable)\n",
    "plt.show()\n",
    "```\n",
    "And you would get the following output:\n",
    "\n",
    "<img src = \"./Figs_README/XiL_v_itheta_example.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6fbf2-b77a-47aa-98e3-aa3b956056f6",
   "metadata": {},
   "source": [
    "##### get_corr_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb1d42-0793-40c4-901e-b72df700e3c0",
   "metadata": {},
   "source": [
    "```python\n",
    "get_corr_func(self,suppress_output = False,**kwargs)\n",
    "```\n",
    "\n",
    "This function returns the average correlation function for the set of parameters specified. This requires returning one single run, so it plays by the same rules as ```get_data``` with ```single_run = True``` and it will tell you if you left out a parameter:\n",
    "\n",
    "```python\n",
    "itheta = np.pi\n",
    "beta = 1.6\n",
    "length = 20\n",
    "nMC = 50000\n",
    "corr_params = {\"itheta\": itheta, \"beta\": beta,\"length\": length,\"nMC\": nMC}\n",
    "G_ij = analyzer.get_corr_func(suppress_output = False, **corr_params)\n",
    "```\n",
    "\n",
    "```\n",
    "Missing parameters in input: \n",
    "['ntherm', 'freq']\n",
    "\n",
    "```\n",
    "When you specify the complete set of parameters, it returns a 2D numpy array that represents the average correlation function on each lattice site. You can then plot this with imshow:\n",
    "```python\n",
    "plt.imshow(G_ij, cmap = \"viridis\", aspect='equal')\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation function for L = \"+str(corr_params[\"length\"])+\", itheta = \"+str(corr_params[\"itheta\"]))\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "and you will get something that looks like this:\n",
    "\n",
    "\n",
    "<img src = \"./Figs_README/Gij_example.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5187f1-bef4-47c8-b841-f0f74b2b8844",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Currently, the simulation returns the average value of the correlation function computed after thermalization. There is no way to change this after the simulation is run, and we don't have the code set up yet to return any error on the correlation function. That may come in future versions of the code.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7bcc8-a98c-475d-823b-afde9ca5d87b",
   "metadata": {},
   "source": [
    "#### Lattice Data Class Built-In Functions (\"Private\" or internal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc586d-3bce-428f-92ef-6502cbcc6bac",
   "metadata": {},
   "source": [
    "##### get_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0201384-1e24-4c08-ac4b-3160af25cc97",
   "metadata": {},
   "source": [
    "```python\n",
    "get_data_files(self, corr = False)\n",
    "```\n",
    "This function is referenced by ```all_params``` and ```get_data``` (which are both in turn called by other functions). \n",
    "\n",
    "It loops through every file in the data directory (```self.path```) set when you initialize the object. If you have set ```corr``` to ```True``` (e.g. as done in the function ```get_corr_func```), it uses ```self.Gheader``` to pick out all the simulation files that are correlation function data and put them in a list. If ```corr``` is ```False```, it uses ```self.header``` to pick out all the regular data files from the simulation and create a list of those.\n",
    "\n",
    "It returns just a list of all the relevant data filenames, which can then be used by other functions to extract the parameters (as in ```all_params```) or make a dataframe (as in ```get_data```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96940e-987e-4105-878d-14c6ad3e4ccb",
   "metadata": {},
   "source": [
    "##### get_file_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea438c-47ea-466c-80a5-05aeb0c280d6",
   "metadata": {},
   "source": [
    "```python\n",
    "get_file_params(self, file)\n",
    "```\n",
    "This function is referenced by ```all_params``` and ```get_data``` (which are both in turn called by other functions). \n",
    "\n",
    "It takes a filename (e.g. one from the list generated by ```get_data_files```) and extracts from that filename the parameter values used in the simulation. It returns a dictionary with the following keys:\n",
    "\n",
    "* \"freq\" -- the number of steps between saved configurations\n",
    "* \"nMC\" -- the number of steps in the Monte Carlo loop\n",
    "* \"ntherm\" -- the number of thermalization steps before beginning the Monte Carlo loop\n",
    "* \"itheta\" -- the value of the parameter $i \\theta$ (actual value, not integer multiples of pi)\n",
    "* \"beta\" -- inverse lattice coupling (currently set to 1.6 for all simulations, but could be changed)\n",
    "* \"length\" -- number of lattice sites in both x and y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08187b7-b7b9-4953-ae25-2a91f5f96079",
   "metadata": {},
   "source": [
    "##### in_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58070aaf-6dc1-448e-a6aa-a13d0ebbbee8",
   "metadata": {},
   "source": [
    "``` python\n",
    "in_list(self,pdict,**kwargs)\n",
    "```\n",
    "This function is only called by ```get_data``` but it serves the important function of managing all the filtering we want to it. It checks each parameter fed into ```get_data``` in the keyword arguments and it checks it against the parameters in the filename for a simulation run. If all the parameter values specified in the keyword arguments match parameters in the file, it returns ```True```, otherwise it returns ```False```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c7ca1-d46b-4f65-90bd-68242335e37d",
   "metadata": {},
   "source": [
    "##### calc_F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cada11-5f17-4825-bb44-0390e5b3d708",
   "metadata": {},
   "source": [
    "```python\n",
    "calc_F(self, **kwargs)\n",
    "```\n",
    "\n",
    "This function calculates the correlation function at the smallest nonzero lattice momentum ($p_{0} = 2 \\pi/L$) . It requires the correlation function for that set of parameters ($G$, which it obtains by calling ```get_corr_func```) and then performs the following calculation, summing over all lattice sites $(x,y)$:\n",
    "\n",
    "$\\mathcal{F} = \\frac{1}{2}\\sum_{x,y}(e^{2 \\pi i x/L} + e^{2 \\pi i y/L})G(x,y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e4165-b5bc-4b44-b3ae-187435a8a875",
   "metadata": {},
   "source": [
    "##### calc_corr_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992866b6-431b-4de3-aef5-a6a79527bc1d",
   "metadata": {},
   "source": [
    "```python\n",
    "calc_corr_length(self,Xi,L,F_py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709ba64-ea15-494b-9c85-97b99dd631ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca473327-59b3-49ed-ae35-3e9ad4ea8fe1",
   "metadata": {},
   "source": [
    "#### AnalysisTesting.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8012a-42d1-408d-ad2d-41045f0e7173",
   "metadata": {},
   "source": [
    "#### PhiDist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232c1f2-fddb-4761-b38e-4a4cb763f029",
   "metadata": {},
   "source": [
    "#### DataComparison.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413a8e9-3aff-413f-83ce-96e62a051b5f",
   "metadata": {},
   "source": [
    "#### SystematicsAndTiming.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d789686-0c65-4635-8b56-860d1f39c7d8",
   "metadata": {},
   "source": [
    "#### CorrelationFunction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50b05f-2023-43d3-90c3-548408e89fb6",
   "metadata": {},
   "source": [
    "#### Observables.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84726f69-add5-4d44-84d1-1ac4015a7efc",
   "metadata": {},
   "source": [
    "## Summary of Preliminary Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af6cab-bb9e-42d2-8685-8c556d4434c3",
   "metadata": {},
   "source": [
    "Preliminary simulation code is being run on small lattices ($L = 10,40,80$) with the intent to scale to larger lattices in the next few months.\n",
    "\n",
    "Early results look promising. For example, when comparing our results for the topological charge QL to those of Allés et al, we see a similar trend in the data:\n",
    "\n",
    "<img src = \"./Figs_README/AllesPRBQ_L.png\" width=\"425\"/><img src = \"./Figs_README/Q_L_preliminary.jpg\" width=\"425\"/>\n",
    "\n",
    "We expect as the size of the lattice grows (to 180 x 180, as was used in the PRB paper), our $Q_L$ plot should match theirs. Simulations at L = 180 are currently underway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16565b7-c14e-4b27-a26b-cec50e66a38c",
   "metadata": {},
   "source": [
    "## Current issues and open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c9648-126b-458e-8d8c-9828b7a2f07e",
   "metadata": {},
   "source": [
    "Issues we are working on resolving:\n",
    "* The topological charge calculation ($Q_{L}$) is currently returning non-integer values\n",
    "* The correlation function at the smallest nonzero lattice momentum $2\\pi/L$ is a complex number, therefore so is our correlation length. Correlation length at imaginary $\\theta$ should be real \n",
    "* Additionally, when this value is computed in C++, the results are significantly off from the calculation done in Python\n",
    "* Currently, the simulation returns the average value of the correlation function computed after thermalization. There is no way to change this after the simulation is run, and we don't have the code set up yet to return any error on the correlation function. That may come in future versions of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2947a8-025f-491c-bf9c-769eddf1791f",
   "metadata": {},
   "source": [
    "Research questions and next steps\n",
    "* What can a ML model learn from the configuration data we have so far?\n",
    "* How will Complex Langevin results differ from these if at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1735349-3c49-49ed-a342-619cf50faf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
